{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from time import perf_counter\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.utils\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline  \n",
    "print(torch.cuda.is_available())\n",
    "cifar_mean_stddev = ((0.49139968,  0.48215841,  0.44653091), (0.24703223,  0.24348513,  0.26158784))\n",
    "train_ratio=0.8\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILS\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "class Private_Image_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        load_data = np.load(data_dir+\"\\private_test_images_v3.npy\")\n",
    "        self.data=load_data.reshape(2000, 32, 32, 3)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        x = Image.fromarray(img)\n",
    "        x = self.transform(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "cifar_mean_stddev = ((0.49139968,  0.48215841,  0.44653091), (0.24703223,  0.24348513,  0.26158784))\n",
    "\n",
    "def display_batch(dataset_loaded, test=False):\n",
    "    (mean, stddev)=cifar_mean_stddev\n",
    "    mean = torch.tensor(mean).reshape(1,3,1,1)\n",
    "    stddev = torch.tensor(stddev).reshape(1,3,1,1)\n",
    "    if test:\n",
    "        for images in dataset_loaded:\n",
    "            fig, ax = plt.subplots(figsize = (10,10))\n",
    "            images = images * stddev + mean\n",
    "            ax.imshow(make_grid(images,nrow=10).permute(1,2,0))\n",
    "            fig.savefig('test_batch.png', dpi=200) \n",
    "            break\n",
    "    else: \n",
    "        for images, labels in dataset_loaded:\n",
    "            fig, ax = plt.subplots(figsize = (10,10))\n",
    "            images = images * stddev + mean\n",
    "            ax.imshow(make_grid(images,10).permute(1,2,0))\n",
    "            fig.savefig('batch.png', dpi=200) \n",
    "            print(labels)\n",
    "            break\n",
    "\n",
    "#Reference: https://pytorch.org/tutorials/beginner/nn_tutorial.html#wrapping-dataloader\n",
    "\n",
    "def get_torch_device():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    return device\n",
    "\n",
    "def move_to_device(object, device):\n",
    "    if (isinstance(object, (list, tuple))):\n",
    "        # tensor = tf.convert_to_tensor(array)\n",
    "        return [move_to_device(obj, device) for obj in object]\n",
    "    elif isinstance(object, dict):\n",
    "        return [(k, move_to_device(v, device)) for k,v in object.items]\n",
    "    else:\n",
    "        return object.to(device=device, non_blocking = True)\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dataset_loaded):\n",
    "        self.dataset_loaded = dataset_loaded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_loaded)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dataset_loaded)\n",
    "        for b in batches:\n",
    "            yield (move_to_device(b, device=get_torch_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGEUTILS\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\"\"\"This script implements the functions for data augmentation\n",
    "and preprocessing.\n",
    "\"\"\"\n",
    "\n",
    "#UNUSED METHOD\n",
    "def parse_record(record, training):\n",
    "    \"\"\"Parse a record to an image and perform data preprocessing.\n",
    "\n",
    "    Args:\n",
    "        record: An array of shape [3072,]. One row of the x_* matrix.\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    depth_major = record.reshape((3, 32, 32))\n",
    "\n",
    "    # Convert from [depth, height, width] to [height, width, depth]\n",
    "    image = np.transpose(depth_major, [1, 2, 0])\n",
    "\n",
    "    image = preprocess_image(image, training)\n",
    "\n",
    "    # Convert from [height, width, depth] to [depth, height, width]\n",
    "    image = np.transpose(image, [2, 0, 1])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    image = preprocess_image(image, training) # If any.\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess_image():\n",
    "    \"\"\"Preprocess a single image of shape [height, width, depth].\n",
    "\n",
    "    Args:\n",
    "        image: An array of shape [32, 32, 3].\n",
    "        training: A boolean. Determine whether it is in training mode.\n",
    "\n",
    "    Returns:\n",
    "        preprocess_train, preprocess_test: Transformations for train and test preprocessing.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    #Reference for stats values: https://github.com/Armour/pytorch-nn-practice/blob/master/utils/meanstd.py\n",
    "    cifar_mean_stddev = ((0.49139968,  0.48215841,  0.44653091), (0.24703223,  0.24348513,  0.26158784))\n",
    "    #Tutorial for using pytorch transforms:https://pytorch.org/vision/stable/auto_examples/plot_scripted_tensor_transforms.html\n",
    "    preprocess_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32,padding = 4, padding_mode = 'reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*cifar_mean_stddev, inplace=True) \n",
    "    ])\n",
    "    \n",
    "    preprocess_test = transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "        transforms.Normalize(*cifar_mean_stddev, inplace=True)\n",
    "    ])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return (preprocess_train, preprocess_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATALOADER\n",
    "\n",
    "from Utils import Private_Image_Dataset, WrappedDataLoader, display_batch\n",
    "from ImageUtils import preprocess_image\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\"\"\"This script implements the functions for reading data.\n",
    "\"\"\"\n",
    "batch_size=64\n",
    "\n",
    "def load_data(data_dir=''):\n",
    "    \"\"\"Load the CIFAR-10 dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir: A string. The directory where data batches\n",
    "            are stored/will be downloaded.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset_loaded: Training Dataset\n",
    "        valid_dataset_loaded: Validation Dataset\n",
    "        cifar_test_dataset_loaded: CIFAR-10 Test Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    input_train_dataset = torchvision.datasets.CIFAR10(root = data_dir, download = True, transform = preprocess_image()[0])\n",
    "    cifar_test_dataset = torchvision.datasets.CIFAR10(root = data_dir, download = True, transform = preprocess_image()[1], train = False)\n",
    "    \n",
    "    train_dataset, valid_dataset = train_valid_split(input_train_dataset)\n",
    "    train_dataset_loaded = DataLoader(train_dataset, batch_size, shuffle = True, pin_memory = True)\n",
    "    valid_dataset_loaded = DataLoader(valid_dataset, batch_size, shuffle = True, pin_memory = True)\n",
    "    cifar_test_dataset_loaded = DataLoader(cifar_test_dataset, batch_size, shuffle = True, pin_memory = True)\n",
    "    \n",
    "    train_dataset_loaded = WrappedDataLoader(train_dataset_loaded)\n",
    "    valid_dataset_loaded = WrappedDataLoader(valid_dataset_loaded)\n",
    "    cifar_test_dataset_loaded = WrappedDataLoader(cifar_test_dataset_loaded)\n",
    "    display_batch(cifar_test_dataset_loaded)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return train_dataset_loaded, valid_dataset_loaded, cifar_test_dataset_loaded\n",
    "\n",
    "def load_private_testing_images(data_dir):\n",
    "    \"\"\"Load the images in private testing dataset.\n",
    "\n",
    "    Args:\n",
    "        data_dir: A string. The directory where the testing images\n",
    "        are stored.\n",
    "\n",
    "    Returns:\n",
    "        private_test_dataset_loaded: Private Test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    private_test_dataset=Private_Image_Dataset(data_dir, transform=preprocess_image()[1])\n",
    "    private_test_dataset_loaded = DataLoader(private_test_dataset, batch_size, shuffle = False, pin_memory = True, num_workers=2)\n",
    "    private_test_dataset_loaded = WrappedDataLoader(private_test_dataset_loaded)\n",
    "    display_batch(private_test_dataset_loaded, test=True)\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return private_test_dataset_loaded\n",
    "\n",
    "def train_valid_split(input_train_dataset, train_ratio=0.8):\n",
    "    \"\"\"Split the original training data into a new training dataset\n",
    "    and a validation dataset.\n",
    "\n",
    "    Args:\n",
    "        input_train_dataset: Input training dataset\n",
    "        train_ratio: A float number between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset: Training dataset of length train_ratio*x_train.shape.\n",
    "        valid_dataset: Validation dataset of length [1-train_ratio]*x_train.shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    split_index=int(train_ratio* len(input_train_dataset))\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "        dataset = input_train_dataset, \n",
    "        lengths = [split_index, len(input_train_dataset)-split_index],\n",
    "        generator = torch.Generator().manual_seed(42))\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6ad16f1877d4fae9ebab23d86c8c550a4bd47bd57f94d416d909c4af9e7ba9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
